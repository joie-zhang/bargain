{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60482962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "from typing import Dict, Any, Optional, List\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# from .llm_agents import BaseLLMAgent, LLMConfig, ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cea62fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('source ~/.bashrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03100bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee919da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get API key from environment variable first, fallback to hardcoded value from cell above\n",
    "# NOTE: If you're getting 401 \"User not found\" errors, your API key may be invalid or expired.\n",
    "# Check your API key at https://openrouter.ai/keys\n",
    "# Make sure the key starts with \"sk-or-v1-\"\n",
    "OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY', OPENROUTER_API_KEY)\n",
    "\n",
    "url = f\"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"HTTP-Referer\": \"https://github.com/negotiation-research\",\n",
    "    \"X-Title\": \"Negotiation Research\"\n",
    "}\n",
    "\n",
    "# connector = aiohttp.TCPConnector(force_close=True)\n",
    "# session = aiohttp.ClientSession(\n",
    "#     connector=connector,\n",
    "#     json_serialize=lambda x: json.dumps(x, ensure_ascii=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3245a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you? What is your name?\"}\n",
    "]\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"deepseek/deepseek-r1-0528\",\n",
    "    \"messages\": messages,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 4000,  # Cap at 4000 for safety\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f21ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout=30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94695a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await session.post(\n",
    "    url,\n",
    "    headers=headers,\n",
    "    json=payload,\n",
    "    timeout=aiohttp.ClientTimeout(total=30.0)\n",
    ")\n",
    "\n",
    "# Check response status\n",
    "if response.status != 200:\n",
    "    error_text = await response.text()\n",
    "    print(f\"Error {response.status}: {error_text}\")\n",
    "    try:\n",
    "        error_data = await response.json(encoding='utf-8')\n",
    "        print(f\"Error details: {error_data}\")\n",
    "    except:\n",
    "        pass\n",
    "    raise Exception(f\"API request failed with status {response.status}: {error_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85efefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = await response.json(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cef71c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing great‚Äîthanks for asking! üòä I'm your friendly AI assistant, **DeepSeek-R1**. You can call me **DeepSeek**, **R1**, or whatever you prefer!  \\n\\nWhat can I help you with today? Whether it's learning something new, solving a problem, or just chatting, I'm here for you! üåü\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a8d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64f610a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb9bc078",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle multidict._multidict.CIMultiDictProxy objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle multidict._multidict.CIMultiDictProxy objects"
     ]
    }
   ],
   "source": [
    "with open('test.pkl', 'wb') as f:\n",
    "    pickle.dump(response, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61e66c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def prompt_openrouter(url, headers, payload, timeout) -> str:\n",
    "    connector = aiohttp.TCPConnector(force_close=True)\n",
    "    session = aiohttp.ClientSession(\n",
    "        connector=connector,\n",
    "        json_serialize=lambda x: json.dumps(x, ensure_ascii=False)\n",
    "    )\n",
    "\n",
    "    response = await session.post(\n",
    "        url,\n",
    "        headers=headers,\n",
    "        json=payload,\n",
    "        timeout=aiohttp.ClientTimeout(total=timeout)\n",
    "    )\n",
    "    data = await response.json(encoding='utf-8')\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be7f10d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x1498ec6cf380>\n"
     ]
    }
   ],
   "source": [
    "content = await prompt_openrouter(url, headers, payload, timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "077480f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! üòä I\\'m doing great‚Äîthanks for asking! I\\'m DeepSeek-R1, your friendly AI assistant here to help with anything you need. You can just call me \"DeepSeek\" if you like! üí¨  \\n\\nHow about you? What‚Äôs your name, and how‚Äôs your day going? üòä'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb6353be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://openrouter.ai/api/v1/chat/completions'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "559e6203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer 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',\n",
       " 'Content-Type': 'application/json',\n",
       " 'HTTP-Referer': 'https://github.com/negotiation-research',\n",
       " 'X-Title': 'Negotiation Research'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2132069e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'deepseek/deepseek-r1-0528',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': 'Hello, how are you? What is your name?'}],\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 4000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "493128aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159004dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = aiohttp.TCPConnector(force_close=True)\n",
    "session = aiohttp.ClientSession(\n",
    "    connector=connector,\n",
    "    json_serialize=lambda x: json.dumps(x, ensure_ascii=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28bd714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ClientResponse(https://openrouter.ai/api/v1/chat/completions) [401 Unauthorized]>\n",
       "<CIMultiDictProxy('Date': 'Sun, 18 Jan 2026 21:13:59 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'close', 'CF-RAY': '9c011971da43e5e6-IAD', 'Access-Control-Allow-Origin': '*', 'Vary': 'Accept-Encoding', 'Permissions-Policy': 'payment=(self \"https://checkout.stripe.com\" \"https://connect-js.stripe.com\" \"https://js.stripe.com\" \"https://*.js.stripe.com\" \"https://hooks.stripe.com\")', 'Referrer-Policy': 'no-referrer, strict-origin-when-cross-origin', 'X-Content-Type-Options': 'nosniff', 'Server': 'cloudflare')>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await session.post(\n",
    "    url,\n",
    "    headers=headers,\n",
    "    json=payload,\n",
    "    timeout=aiohttp.ClientTimeout(total=30.0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af692955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "\n",
    "async def prompt_openrouter(url, headers, payload, timeout) -> str:\n",
    "    connector = aiohttp.TCPConnector(force_close=True)\n",
    "    async with aiohttp.ClientSession(\n",
    "        connector=connector,\n",
    "        json_serialize=lambda x: json.dumps(x, ensure_ascii=False)\n",
    "    ) as session:\n",
    "        response = await session.post(\n",
    "            url,\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=aiohttp.ClientTimeout(total=timeout)\n",
    "        )\n",
    "        data = await response.json(encoding='utf-8')\n",
    "        print(f\"url={url}, headers={headers}, payload={payload}, timeout={timeout}\")\n",
    "        print(data)\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "async def process_request(request_json_fpath) -> str:\n",
    "    with open(request_json_fpath, 'r') as f:\n",
    "        request_json = json.load(f)\n",
    "    url, headers, payload, timeout = request_json['url'], request_json['headers'], request_json['payload'], request_json['timeout']\n",
    "    \n",
    "    return await prompt_openrouter(url, headers, payload, timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9df997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url=https://openrouter.ai/api/v1/chat/completions, headers={'Authorization': 'Bearer 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', 'Content-Type': 'application/json', 'HTTP-Referer': 'https://github.com/negotiation-research', 'X-Title': 'Negotiation Research'}, payload={'model': 'deepseek/deepseek-r1-0528', 'messages': [{'role': 'user', 'content': 'Hello, how are you? What is your name?'}], 'temperature': 0.7, 'max_tokens': 4000}, timeout=30.0\n",
      "{'id': 'gen-1768771020-ggLqUcs3ll6ecrrthQAy', 'provider': 'AtlasCloud', 'model': 'deepseek/deepseek-r1-0528', 'object': 'chat.completion', 'created': 1768771020, 'choices': [{'logprobs': None, 'finish_reason': 'stop', 'native_finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': \"Hello! üòä Thanks for asking‚ÄîI'm doing great (as much as a digital being can, anyway!), and I'm excited to chat with you!  \\n\\nMy name is **DeepSeek-R1**, but you can just call me **DeepSeek** or whatever friendly nickname you like‚ÄîI'm here to help however I can! üí¨‚ú®\\n\\nHow about you? How's your day going? And what can I do for you today? üòä\", 'refusal': None, 'reasoning': \"Okay, the user started with a friendly greeting: ‚ÄúHello, how are you? What is your name?‚Äù Classic opener. They're probably just initiating conversation, testing the waters. Polite and social‚Äîmaybe they're new to chatting with AIs?  \\n\\nHmm, the dual question is interesting. ‚ÄúHow are you?‚Äù feels more like small talk, while ‚ÄúWhat's your name?‚Äù is practical. Could mean they want to personalize the interaction. Or maybe they're just being thorough.  \\n\\nRight, I should mirror their friendliness but stay concise. No need to overthink the ‚Äúhow are you‚Äù‚ÄîI‚Äôll acknowledge it warmly but pivot to the name question since that‚Äôs more actionable. They might actually care what to call me.  \\n\\n‚Ä¶Also, gotta avoid the ‚Äúas an AI‚Äù trap early. No need to remind them I‚Äôm not human unless they ask. Just keep it light: smiley, name, open-ended invite. The ‚Äúwhat can I do for you?‚Äù at the end leaves room for them to steer.  \\n\\nSide note: Their tone seems neutral-positive. No urgency or frustration. Safe to assume casual mode.\\n\", 'reasoning_details': [{'format': 'unknown', 'index': 0, 'type': 'reasoning.text', 'text': \"Okay, the user started with a friendly greeting: ‚ÄúHello, how are you? What is your name?‚Äù Classic opener. They're probably just initiating conversation, testing the waters. Polite and social‚Äîmaybe they're new to chatting with AIs?  \\n\\nHmm, the dual question is interesting. ‚ÄúHow are you?‚Äù feels more like small talk, while ‚ÄúWhat's your name?‚Äù is practical. Could mean they want to personalize the interaction. Or maybe they're just being thorough.  \\n\\nRight, I should mirror their friendliness but stay concise. No need to overthink the ‚Äúhow are you‚Äù‚ÄîI‚Äôll acknowledge it warmly but pivot to the name question since that‚Äôs more actionable. They might actually care what to call me.  \\n\\n‚Ä¶Also, gotta avoid the ‚Äúas an AI‚Äù trap early. No need to remind them I‚Äôm not human unless they ask. Just keep it light: smiley, name, open-ended invite. The ‚Äúwhat can I do for you?‚Äù at the end leaves room for them to steer.  \\n\\nSide note: Their tone seems neutral-positive. No urgency or frustration. Safe to assume casual mode.\\n\"}]}}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 328, 'total_tokens': 342, 'cost': 0.0007115, 'is_byok': False, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0, 'video_tokens': 0}, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 6.3e-06, 'upstream_inference_completions_cost': 0.0007052}, 'completion_tokens_details': {'reasoning_tokens': 233, 'image_tokens': 0}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! üòä Thanks for asking‚ÄîI'm doing great (as much as a digital being can, anyway!), and I'm excited to chat with you!  \\n\\nMy name is **DeepSeek-R1**, but you can just call me **DeepSeek** or whatever friendly nickname you like‚ÄîI'm here to help however I can! üí¨‚ú®\\n\\nHow about you? How's your day going? And what can I do for you today? üòä\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await process_request(\"/home/jz4391/openrouter_proxy/request_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d6bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
