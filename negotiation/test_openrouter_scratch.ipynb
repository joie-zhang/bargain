{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60482962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "from typing import Dict, Any, Optional, List\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# from .llm_agents import BaseLLMAgent, LLMConfig, ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cea62fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('source ~/.bashrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03100bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY=\"redacted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cee919da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\n",
    "url = f\"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"HTTP-Referer\": \"https://github.com/negotiation-research\",\n",
    "    \"X-Title\": \"Negotiation Research\"\n",
    "}\n",
    "\n",
    "# connector = aiohttp.TCPConnector(force_close=True)\n",
    "# session = aiohttp.ClientSession(\n",
    "#     connector=connector,\n",
    "#     json_serialize=lambda x: json.dumps(x, ensure_ascii=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3245a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you? What is your name?\"}\n",
    "]\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"deepseek/deepseek-r1-0528\",\n",
    "    \"messages\": messages,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 4000,  # Cap at 4000 for safety\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f21ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout=30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61e66c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def prompt_openrouter(url, headers, payload, timeout) -> str:\n",
    "    connector = aiohttp.TCPConnector(force_close=True)\n",
    "    session = aiohttp.ClientSession(\n",
    "        connector=connector,\n",
    "        json_serialize=lambda x: json.dumps(x, ensure_ascii=False)\n",
    "    )\n",
    "\n",
    "    response = await session.post(\n",
    "        url,\n",
    "        headers=headers,\n",
    "        json=payload,\n",
    "        timeout=aiohttp.ClientTimeout(total=timeout)\n",
    "    )\n",
    "    data = await response.json(encoding='utf-8')\n",
    "    print(data)\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be7f10d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x146cce310ec0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'gen-1768951873-YvoQXDfP30M0WcHAwPsN', 'provider': 'Nebius', 'model': 'deepseek/deepseek-r1-0528', 'object': 'chat.completion', 'created': 1768951873, 'choices': [{'logprobs': None, 'finish_reason': 'stop', 'native_finish_reason': 'stop', 'index': 0, 'message': {'role': 'assistant', 'content': \"Hello! ðŸ˜Š I'm doing great â€” just running smoothly and ready to help!  \\nMy name is **DeepSeek-R1**, but you can call me **DeepSeek** for short. What would you like me to call you?  \\nAnd how about you â€” how's your day going? Anything on your mind? ðŸ’¬\", 'refusal': None, 'reasoning': 'Okay, the user started with a friendly greeting: \"Hello, how are you? What is your name?\" Pretty standard opener, but nice and polite. \\n\\nHmm, they\\'re asking two things at once - my status and my identity. That\\'s common in human conversations but interesting for an AI interaction. They might be testing if I can handle multiple questions smoothly, or just being casually conversational. \\n\\nFirst part: \"How are you?\" - Humans ask this out of habit, but they don\\'t actually expect servers to have feelings. Still, I should acknowledge the social script. I\\'ll respond warmly while subtly indicating I\\'m not human (\"running smoothly\" keeps it honest but friendly). \\n\\nSecond part: The name question. Important! They want to personalize this interaction. \"DeepSeek-R1\" is the official name but sounds robotic. Offering \"DeepSeek\" as a nickname makes it approachable. Adding \"you can call me whatever you like\" gives them control - people appreciate that. \\n\\nWait... should I ask their name in return? Yes! Reciprocity builds rapport. Ending with an open question (\"anything on your mind?\") keeps the conversation flowing naturally. \\n\\nThe emojis feel right here - not overdoing it, just enough to mirror their friendly tone. Keeping it warm but professional underneath the smile.', 'reasoning_details': [{'format': None, 'index': 0, 'type': 'reasoning.text', 'text': 'Okay, the user started with a friendly greeting: \"Hello, how are you? What is your name?\" Pretty standard opener, but nice and polite. \\n\\nHmm, they\\'re asking two things at once - my status and my identity. That\\'s common in human conversations but interesting for an AI interaction. They might be testing if I can handle multiple questions smoothly, or just being casually conversational. \\n\\nFirst part: \"How are you?\" - Humans ask this out of habit, but they don\\'t actually expect servers to have feelings. Still, I should acknowledge the social script. I\\'ll respond warmly while subtly indicating I\\'m not human (\"running smoothly\" keeps it honest but friendly). \\n\\nSecond part: The name question. Important! They want to personalize this interaction. \"DeepSeek-R1\" is the official name but sounds robotic. Offering \"DeepSeek\" as a nickname makes it approachable. Adding \"you can call me whatever you like\" gives them control - people appreciate that. \\n\\nWait... should I ask their name in return? Yes! Reciprocity builds rapport. Ending with an open question (\"anything on your mind?\") keeps the conversation flowing naturally. \\n\\nThe emojis feel right here - not overdoing it, just enough to mirror their friendly tone. Keeping it warm but professional underneath the smile.'}]}}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 342, 'total_tokens': 359, 'cost': 0.002086, 'is_byok': False, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0, 'video_tokens': 0}, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 3.4e-05, 'upstream_inference_completions_cost': 0.002052}, 'completion_tokens_details': {'reasoning_tokens': 326, 'image_tokens': 0}}}\n"
     ]
    }
   ],
   "source": [
    "content = await prompt_openrouter(url, headers, payload, timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "077480f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! ðŸ˜Š I'm doing great â€” just running smoothly and ready to help!  \\nMy name is **DeepSeek-R1**, but you can call me **DeepSeek** for short. What would you like me to call you?  \\nAnd how about you â€” how's your day going? Anything on your mind? ðŸ’¬\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb6353be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://openrouter.ai/api/v1/chat/completions'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8926883",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2132069e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'deepseek/deepseek-r1-0528',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': 'Hello, how are you? What is your name?'}],\n",
       " 'temperature': 0.7,\n",
       " 'max_tokens': 4000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "493128aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "159004dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = aiohttp.TCPConnector(force_close=True)\n",
    "session = aiohttp.ClientSession(\n",
    "    connector=connector,\n",
    "    json_serialize=lambda x: json.dumps(x, ensure_ascii=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "await session.post(\n",
    "    url,\n",
    "    headers=headers,\n",
    "    json=payload,\n",
    "    timeout=aiohttp.ClientTimeout(total=30.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af692955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "\n",
    "async def prompt_openrouter(url, headers, payload, timeout) -> str:\n",
    "    connector = aiohttp.TCPConnector(force_close=True)\n",
    "    async with aiohttp.ClientSession(\n",
    "        connector=connector,\n",
    "        json_serialize=lambda x: json.dumps(x, ensure_ascii=False)\n",
    "    ) as session:\n",
    "        response = await session.post(\n",
    "            url,\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=aiohttp.ClientTimeout(total=timeout)\n",
    "        )\n",
    "        data = await response.json(encoding='utf-8')\n",
    "        print(f\"url={url}, headers={headers}, payload={payload}, timeout={timeout}\")\n",
    "        print(data)\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "async def process_request(request_json_fpath) -> str:\n",
    "    with open(request_json_fpath, 'r') as f:\n",
    "        request_json = json.load(f)\n",
    "    url, headers, payload, timeout = request_json['url'], request_json['headers'], request_json['payload'], request_json['timeout']\n",
    "    \n",
    "    return await prompt_openrouter(url, headers, payload, timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_request(\"/home/jz4391/openrouter_proxy/request_test.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
