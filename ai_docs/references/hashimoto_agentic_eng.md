welcome everybody this is the first of our agentic engineering sessions i'm Richard i'm an engineer at Zed we make a code editor that's awesome at AI this is Mitchell Hashimoto uh creator of lots of widely used technologies some of which you may have used most recently the excellent ghosty terminal emulator which is my terminal emulator of choice so thanks by the way for making it um big fan sweet
uh yeah so basically we're here to learn about how people are using AI agents to make highquality software not just make the same old stuff faster ghosty is absolutely something I would count in that high quality like raising the quality bar uh camp and so Mitchell you've been posting about some how like ways that you've been using large language models to make improvements to Ghosty um it's not only you know a high high quality project but it's also lots of low-level systems programming type stuff um you're not like just you know making a web UI or something like that um and it's also in a non- mainstream language namely ZIG and I know there are some sort of like specific challenges around that because it's not super represented in the models training set so why don't we just start with um just talking through like a particular uh commit that you shared where you had sort of like the the prompts that you used and stuff like that um and we can just kind of talk through like what you did how it went like you know what you've learned and sort of like get tactical about like what pieces of advice you might have for uh for people who are looking to do the same kind of stuff
how's that sound
okay that sound sounds great
all right cool so I'm going to just uh share my screen here um so this is the commit uh you talked about uh how like you know this is sort of like
oh yeah
fixing yeah do you want to just give a little context on on what the actual fix was uh yeah so really high level ghost you just shipped this new feature recently in tip it's not like release but it's available for for beta users um where when you close any terminal whether it's like a split a tab a window when you close a terminal you could control z command z to undo it so like for like 5 seconds after you close it configurable amount of time after you close it you could command Z and it pops back up and like it never shuts it down so like all your history is there like everything stays there and so this was um I don't remember it's D specifics but this was a bug related to introducing that feature and that feature was heavily co-written with AI tooling
yeah nice okay so that's sort of like the background so like this is a it's a bug that hopefully is pretty understandable like you know undo you want to like re reopen the tab um and that type of stuff uh y talked about sort of like here's what the implementation needs to do and then below that you had sort of the the prompts that like you you went through to actually get to to the implementation so first question
and also this this commit message is mostly human written as well so just just background
yeah you can kind of tell i mean Claude's got a certain voice it's not my favorite writing voice um yeah okay so uh so the implementation here so first question I have for you is sort of like did you start with breaking it down in this way like did you write these bullet points up front or was it more like you just started with this actual prompt and then you kind of ended up summarizing this like after you'd already finished uh doing the whole thing
yeah so I think that my approach to using AI tooling for now I mean if if the AI tooling gets a lot better then maybe I could get away from this but the way I have the most success is that I feel like I'm more or less um I know people don't like these titles anymore but I'm more or less like the architect of the software project um so I still like to come up with sort of the code structure the expected sort of data flow through the app um where state lives things like that like I like to know that and imagine that in my head and I give tooling that guidance where it's like I want you to achieve this end goal but using this shape um and I find that that leads to most success if I just say like if I had just come into this and said like oh uh this first sentence like this first paragraph here when closing window contains multiple tabs the undo operation uh doesn't work please fix it like if I had done that it probably would have done it but it would have done it in like a terrible you know hammer meets nail like way that that isn't sort of maintainable long term so yeah I I sort of come up I didn't come up with these specific bullet points but you could actually see in my prompt what I said what I told it but I came up with the shape of of how to solve the problem and and let it go
okay okay so so before we go through the individual prompts I want to uh follow up a little bit on something you just kind of implied which is like it sounds like you've tried giving it the even more zoomed out version where you said like here's the behavior here's what I want it to do just go make the thing do what I want it to do and it sounds like you were not happy with the outcome of that approach uh I didn't try with this specific thing i just through practice I now avoid it but yeah in the in the past I wasn't happy with the approach i felt like it took a lot more massaging to get to what I wanted i think because a lot of times I had in my head a vision of what I wanted and like why not just tell it that vision um the only time I sort of used really open-ended ones I I call them like Hail Mary you know they're like zero shot like Hail Mary prompts um is uh I do have like a sa a saved um I forgot they call it claude like slash command um where I just give it an issue number and it connects to GitHub and like pulls down the issue and basically I don't say fix the issue I don't trust it enough to do that yet but I will sort of just the Hail Mary like as I'm triaging issues just say like why does this issue exist do you see a solution and I try to get it to just sort of explain something and and show me a path to take and I might do that like if I'm triaging issues I might do that across like five issues at once while I'm also like looking at new issues and labeling them and categorizing them and things like that um and you know I'm not looking for the answer i'm just like sometimes it it gets me to the point where I'm like "Oh yeah the bug is probably in that file." And then I can just go finish it out myself
right the the mental model I have for using the tool in that way is it's sort of like a first draft generator where it's like yeah I'm going to look at this code and it's going to teach me something about the problem that I didn't get from just the description but I'm probably just going to throw all this code away and then like do it properly later um
yeah yeah yeah I I like to I really you know I've had the experience of of managing real humans and um even though I'm not in that position anymore you know I've I've been at various sort of like seale level director level and had anywhere from a team of five to a team of you know hundreds underneath me and I sort of treat it as if like what would I ask you know people to do if uh if they existed that are not super like more junior level people I guess but like if I had someone that I could efficiently say like can you please debug this and figure out like why this is happening go off and do it um that's that's try that's how I try to use AI
right okay and then one more thing before we move on to the actual prompt which is so at least the the experience I've had like you you sort of alluded to this with the like the downside of like the code quality and the long-term maintainability i've tried working in a way where I just go from one feature to the next just saying like hey just here's the behavior I want make this thing here's the behavior I want this thing without reviewing the code like without trying to be an architect etc in between and what I found is that it kind of feels like I'm driving into mud where at first it's fine and then the more and more times I do that the the slower and slower each iteration gets because every time it makes a new change it breaks previous things and eventually it's just I'm just totally stuck in the mud and really unhappy with where the code base has ended up so that's how I've ended up in the place that you are i'm curious if that's a similar experience you've had yeah I think that I think that the more vague and the longer you let AI spend on something uh the more of a mess it's going to make to get get to the end goal but it it does a surprising amount of time reach that end goal by some definition it's just Yeah it's just like how are you going to iterate on that and maintain it going forward is hard to answer
right all right cool so let's go through the uh the specific prompts that you use so you mentioned that like you know these bullet points came after the fact so this is like what you started with was blank slate you just read the issue and then here's here's where you uh kick things off
yep yeah exactly cool all right so um I don't know do you want to go through like sort of what your thought process was and like like why you wrote the prompts in this way yeah i mean let me I'm just going to read it out loud because I think this is exactly this is exactly what I would tell again if I had a team and I had a junior engineer that was new on the project and this was a well scoped problem for them this is probably what I would tell them i find that when I have junior engineers um sending them off on open-ended problems is to start is a disaster and AI sort of in that state right now like the best way I found to coach juniors is to give them a well scoped problem um with a lot of guardrails on how to uh you know it's sort of like bowling with bumpers so that they could they could reach the end they could reach the pins and you sort of put the guardrails along the way so that's what I did here so the prompt is um I'm just going to read it out verbatim
yeah uh we we need to update the undo redo implementation in this file in the close window immediately function to handle the case that multiple windows in a tab group are closed all at once and to restore them as a tabbed window to do this I think we should collect all the undo states sort them by their tab index with null at the end uh and then on restore restore them one at a time but add them back to the same tab group we can't use the tab group in the undo state because it will be garbage collected by then so to be sure we should just set that to nil and that's what I started with that's probably what I would send off somebody on a vision quest to to try to do
yeah so I definitely see what you mean about you know the metaphor of like this is somebody who's maybe earlier in their career and like because this is you know if I were talking to somebody who was really really experienced I probably wouldn't get this detailed about the code like I wouldn't say like
not at all collect all the undo states sort the vitav decks right um I also noticed like I don't know if this is something you do intentionally or not but for me when I make a little typo like this or something like this little stray J here I don't bother fixing it because they don't seem to confuse the model
with a human I probably might just as a courtesy but I was like ah it's fine
no yeah i don't I don't correct my spelling i don't correct my typos and sometimes I'll use the wrong term and I'm like ah it'll figure out what I mean there so yeah I I I don't do that
yeah and yeah in in this case like you could the another thing to to sort of consider is that you know I'm telling it a solution I would try and you could sort of tell by my prompting that I am very very familiar with the architecture of this code i have a pretty good understanding of what the bug is um you know it it's one of those things where like I had a good understanding but I just I didn't want to write it like this is kind of this is kind of boring to me so I just it was much easier and faster for me to write this paragraph and send it off than for me to spend the time writing it yeah I I definitely had that same kind of experience um cool okay so uh let's let's kind of keep moving along here so you mentioned that like okay at this point feature already worked code quality organization wasn't up to your standards now I'm assuming this is like after you gave it the prompt it ended up with something that was working but not what you were happy with
yep yeah and this for what it's working on here is the Swift part uh of the Mac OS app of [ __ ] not the Zigg part and it doesn't due to like the weird architecture of the Zig and Swift um Claude actually can't currently uh if it's pretty bad at being able to build and run the project um and also like as far as I know it's not going to like look at screenshots and know this is working like there's no way for it to report back and know what it did work so I've disabled any of its self test um in my sort of system prompt for it for this project and uh after it works usually the first thing I do is run a diff just to make sure there's nothing like totally crazy in there like it didn't for some you know unknown reason introduce like a subprocess to delete my file system or something um so I'll just look at that and then I just go to Xcode command R which is run and I just like run it like I don't really look at the code at all i'm like let's just see if this worked at all um and what I did at this point was when I ran it I was like "Okay yeah it is fixed." And then I'll back up and be like "How did they fix it?"
Right yeah there's always that that question of like "Which one do you start with do you start by looking at the code to see if it's acceptable or do you start by like trying to verify if it actually works?" Like you mentioned ideally you have a way that the agent itself can like get in its own loop and verify whether it's fixed like through a test or something else but yeah sometimes I've also hit that thing where it's like yeah I don't have a way to automate this or at least not using my current setup i don't know if you've tried like um getting an agent to automate that like to try to get it to write like a rules file for like here's how you could programmatically do this and take screenshots and stuff like that or is that just sort of a
I'm not there yet
it'd be cool but I'm just not there yet yeah
yeah I'm in the same boat with testing zed stuff it's like yeah it'd be great if we could get it to somehow ask the system to take screenshots and check the output but not there yet um okay cool so we got you got something that the bug appears to be fixed as far as you can tell and I also know from experience that sometimes appearances can be deceiving where it's like well in the most obvious case it's fixed but there's a bunch of edge cases that are just completely ignored um I don't know if that happened here or not but but okay so you
there is one later yeah
yeah but I'll be honest at this point I hadn't found those edge cases yet all I saw at this point was that superficially the way the code looked wasn't what I wanted so my mind was shifting at this point to like the bug is fixed but now let's massage this into like what I actually want to see and it's sort of a trade-off between like do I just go in there manually and do that now um in this case there was just some obvious like I think it could it could do these real quick um to get there so yeah
yeah so so that's sort of like you know you could take out your scalpel and go in and make the cuts yourself or you could be like look here's where the cuts need to be you know just just go do it um cool you want to talk about this a little bit so you mentioned sort of like this uh this gap between the sort of it works versus like it works and is maintainable being something that current generation of large language models don't seem to be great at
yeah yeah and I I think we've touched on this a little bit but and I it's very very similar to people um is when I've hired people straight out of college or or before earlier if they didn't go to college um uh usually what ends up happening is like their skills to achieve a task are fine like they achieved that task they were like we whether it's at a boot camp or at a CS program they were trained to do that and they're able to do it the problem comes into like they're much less experienced contributing some incremental change to a large codebase that's maintained by dozens of people and it's the same thing here and so like a lot of times LLMs to me will produce code that fixes it like you know as direct line as possible but when I look about how we're going to continue to fix bugs how we're going to verify this doesn't regress how are other people on the team going to understand this um things like that like it's not very good at that so Um this paragraph just sort of uh mentioning how like I I think most of the work that that I do do right now with LMS is just getting into more of a senior quality um point of view um but yeah
yeah totally agree i I should have asked this earlier but um do you remember which exact model you used on this
yeah this was um this was uh cloud code tooling using the cloud max plan so um I think it uses uh Opus for a while and then falls back to Sonnet or vice versa i always figure I always forget which one is the the more expensive one but um it's just auto modeling so I think this whole thing though was on the expensive model um I think I still had uh space left yeah this would be Claude 4 Opus which depending on exactly when this was it might have because Ford just came out a couple weeks ago um okay cool uh yeah I always have to like ground that because I've noticed like when talking about large language models in generalizations it's it really varies a lot by model like what kind of behavior they exhibit and so
yeah so I didn't include it in this one i don't think I did it for this piece of work but sometimes what I'll do for piece of work is um I actually have multiple checkouts of ghosty i just go see ghost go 2 ghost 3 go 4 um because you know they can't operate in parallel in the same folder and I will just run different models and different agents on the different code bases on the same task with the same prompt um and that's usually when I'm lower um I I I have less confidence uh but also like it's sort of the same amount of time most of the work's remote anyway you know and so it's like let's just see who who you know it's a competition like if that's something you can't really do with people without getting in a lot of trouble Right
but with machines you could be like "You4 fight to the death." Um and I'll do that and I've so far had the most success with Claude um Gemini was good for a while um but I h I don't know what changed but I haven't liked where 2.5 has gone um it's also just like whenever I ask a simple questions it produces a monumental amount of text as a response it's just it's not efficient to me um so clouds where I have the most um success but because it changes so rapidly I do have them all installed and configured and I just I just sort of run them all uh for other tasks
okay so you've done the parallel checkouts for purposes of like having the same task go on on four different repos at the same time have you also tried doing the like four different problems at the same time kind of workflow uh yeah I've I have and that's more of like the issue the issue side is I'll do that um yeah it's usually not code writing i'm I'm just thinking right now like I I don't think I've had like multiple agents yet working on different problems that I intend to solve it's it's more like multiple agents working on like research and analysis problems for me
i see yeah I I have tried doing that it does get pretty hard to manage the context in my own brain when I get like I I I've got Zed 2 Zed 3 Zed 4 exactly the same thing four different checkouts and then what I have found is if I can find four kind of bite-sized bugs I can just sort of be like hopping between like okay oh this one finished okay go go go go unblock it tell it what to do next oh this one finished go tell it what to do next and then hopefully my goal is to just eventually get them all four in the I'm ready to review it by hand state and then I can do those sequentially
um cool okay uh let's keep going so uh yeah so next
yeah yeah yeah yeah so next I the first thing I identified it i should have brought the intermediate code into this commit i'll try to do that next time but the first thing I noticed was that it solved it by modifying this function and putting all of it in this function so this function went from like let's say 30 lines i don't remember exactly but on the on the order of 30 lines to like 200 lines and you know bigger than than what I could see on my laptop screen and so the first thing I recognized was like okay even though it's not reused code let's like extract some of the logic into the their own self-contained functions and so the prompt I gave it here is let's let's extract all the work you just did into a dedicated private method called register undo for close window um and it went off and did a did a good job there i think that all the agents are really good at refactoring um they're not like fixing bugs or introducing new functionality they're just renaming things and shuffling and restructuring like they're I almost no notes anytime I ask it to do that it's always perfect
yeah now was this a zig method or a swift this is Swift swift
okay got it
um
we could talk about Zigg as well but I would say for Swift at least it's pretty good
yeah okay well so so what what do you think is sort of different in your experience with it doing those types of things for Swift versus Zigg
uh for Swift I mean I think it just has a lot of training material it's it's a more established language um for the for the older functionality in Swift uh is really really good it it produces really good code and um also just really good knowledge about how stuff works um for the newer stuff like if you hop into like Swift concurrency or um uh I I've been doing literally last week this week I've been working on um ghosty compatibility with the new Mac OS 26 Tahoe um announced features and it obviously knows nothing about that so like I'm totally on my own and reading docs and making it all happen and I have tried to just like feed it the new docs as context and it's it's not enough so yeah I I would I've used very little agents the past week i've been I've been back to the the the stone age of just manually learning yeah so I would notice um this is something we've done with rock is we actually have this AI docs link which is basically just like hey here's like an explanation of how this language works that's intended for consumption by a large language model so you can just throw it into your rules file or whatever and it's like you know I'm not saying this is like a a panacea but we have found that like just explicitly having something that gives it extra context on the on the language or even just like a framework or whatever that's not in its training set does seem to help um I haven't tried that for Zig though uh not sure how much it would or wouldn't help um okay cool uh oh yeah the other thing I wanted to note was um you mentioned that like you know this was something where it had it made something that was too long the problem wasn't like that it was uh duplicating code like the the reuse wasn't the issue but rather that it was just like too much jammed in one place i have actually seen actually Cloud4 opus um do the reuse thing where I'm looking at this code this is on the rock compiler which is also in Zigg um it had this like these gigantic chunks of code that were just identical but like very sight things tweaked and I was like
don't do that what are you doing like pull those out into separate function and like call them um but once I asked it to do that yeah it just it just did it and like yeah those types of refactors I really try to avoid doing by hand now because it's just so much faster to ask the the model to do it um
yeah and and when I'm like having this interactive style session like if I'm not using cloud code with like cloud code with like the the dangerously like yolo mode on everything like if I'm doing this interactive thing sometimes right in the middle of it I'll just manually create a commit um I use jiu-jitsu i don't use git so like I don't need to create a commit message or anything i'll just be like snapshot at this point and then continue and that just allows me to like let it try something and instead of saying undo that I'll I'll undo it on the commit and say you're back at the previous state let's try that again and give it a little more guidance of what to do and it it it works really well that makes sense
i think I I wanna it's in my like mental to-do list that I want to try to get some of these agents a little bit more jiu-jitsu aware in order to just be able to like snapshot things i know they could use git already but yeah
have you tried doing like I don't know if you use like a rules file or something like that to like tell it about the project specific stuff that you're working on like I have Yeah I have one locally i don't commit it because I haven't gotten it to work in CI yet and I like want to eventually run this stuff in CI like I want to run it on PR for like do you see anything here like things like that and I I'm it's still a work in progress and and a lot of the complexity comes with the fact that this project requires nyx for the development environments and zig is weird and there's a bunch of weirdness that is sort of self-inflicted so I need to figure that out first
i gotcha is that something you'd be like comfortable sharing or is it like you rather keep it private for now uh yeah private i mean it's messy private for now yeah
okay cool
i'll definitely share it when I finish it
yeah nice i'll look forward to that uh cool okay so moving on um okay so this was where you you just finished this and then you decided to do some manual stuff so this was just like no logic just kind of refactor cleanup type stuff this is just like in your editor of choice uh traditional programming I guess yeah this is like I'm like if I the amount of words I would use to ask it to fix this is the same that I would just like like it's less keystrokes for me to fix this myself so I I went in and nothing was broken again it was just like over commented some stuff delete those comments compress some lines together uh move some logic like a basic block of something up here instead of down there like just you know functionally didn't change anything it just made more sense to like you know check the conditional first before doing work rather than doing the work and then checking the conditional that's unrelated you know stuff like that um yeah
I gotcha okay so now I'm assuming your editor of choice here is Vim like that you're a long time right so right so Neovim uh Neovim for this type of stuff and then you mentioned Claude Code I think for the for the other stuff right
yeah yeah and if I'm working on Swift sometimes it'll by necessity have to be Xcode um begrudgingly but uh a lot of times if I'm in an agent session I'll just actually even still do Swift in
in Neoim just because I don't need to like the autocomplete or any of the other Xcode features i'm actually just text editing and Yeah
and then you just use Xcode to run it I guess when you need to try it out
yeah yeah yeah and it's just sort of like less context switching because I could have cloud code like in a split on the left and I could have neim in a split on the right and I'm just in my terminal yeah yeah that makes sense um cool do you have a sense by the way like I I know that like this commit you know you did a lot of detail here my sense is that this is a pretty new thing for Ghosty but it sounds like you're thinking a lot about like having it in CI and so forth that like you're planning on using it more and more but at least like today I'm guessing that like code generated by LMS is still a pretty small percentage of Go's codebase is that right
oh yeah yeah yeah yeah for sure i would say code generated by LMS and GOC within the last two months it's probably higher i mean it's still probably like less than 25% but it's higher um if you take obviously the the full Ghost project sure it's like less than a percent for sure
gotcha so um going back to like uh like Vim and Xcode and like autocomplete and stuff like that um you said on an interview like a while back that you you you tend to be pretty minimalistic with your editor like um Neoim but not only Neoim but like with pretty minimal plugins like autocompletes and stuff like that um I'm guessing that is still the same so it's sort of like when you're editing code you want the same experience as you're familiar with but then you have this like totally separate like now I'm in agent mode and now I'm in editor mode like those two don't don't blur together for you
yeah I did add like I do have a Neovim plugin called Code Companion which is sort of like a Gentic session thing within directly within Neov but I've honestly just found it easier to use an external process like cloud code um and then other than that yeah I still don't use LSDs i don't nothing built into NeoM obviously like I'll use a debugger but I do it um outside in its own thing and yeah my my terminal sessions are really simple um my editor sessions are really simple and that hasn't really changed it was actually I would say like the rise of LLMs like when that first came up when when I was I did like a that that podcast where someone asked what my neomm setup was like and he was kind of shocked to learn that there's nothing there um you know LM were still so brand new like people weren't even really like chat GBT had just come out and people were still just like asking a dumb question like describe this person um or like plan a fake trip you know they're just doing toy things and uh ever since the rise of sort of the power of these tools I would say like my ability to avoid language servers and stuff has only increased like it's gotten better enough that like like my autocomplete is just like tab completion through models and people people think that's crazy but I'm like if you have like a lot of these tools like generate the right context like open buffer and stuff they generate the right context where like I don't need real like language server knowledge like it generates the right correct tab complete like 95% of the time and that's good enough for me so yeah
yeah I that makes sense um okay cool so uh so moving on all right so now we're uh we're done with the manual edits and then now this I'm I'm guessing all of this is just sort of like back and forth like prompts like these these are just like you did this you said this prompt it did the thing you had this prompt it did the thing back and forth
yeah all the blank lines between the block quote style here is separate prompts but from this point forward I never touched anything manually again it was all LLM driven yeah now I noticed that like the types of things you're talking about here are basically just like hey here's a code cleanup here's a code cleanup looking at your code for this conditionals are a little messy can you make your own path at cleaning those up i thought that was it was pretty cool to see that like you have in some cases you have a very specific here's what I want you to do and then in this one you were more like this is kind of a mess use your own judgment to make it less of a mess yeah and I think it's it's based on whether I know exactly what I would do or whether I I know there's a better way but I have I don't want to my like the point of using this is I don't want to think about it yet so the first two I knew exactly what I was going to do and I just like wanted it to do it um and I felt like it was easier to ask it than to do it myself and then this third one that you have highlighted is yeah great example is like I knew that there was like a block of if if else if like nested through and it was building up a variable and I knew there was probably some sort of like functional like map compact map filter like something something it could do but I didn't know exactly and I so I figured it could do it and I gave it a chance and it it did you can see at the beginning of the next prompt you don't need to tell this but I'm like yeah perfect you did it
yeah I I definitely um this is one of those examples i do the same thing like sometimes I'm very specific about what I want and then sometimes I'm like it's mess and I don't really want to think about what I want i just want you to make it better and then sometimes it succeeds sometimes it fails or sometimes it comes up with something and I'm like oh now that I've seen this actually I do know what I want and it's it's not this but then I'll just I'll give it more specific directions um
yeah I've also had a common case where I think there's a cleaner way to do something i'll ask it to do it cleaner and it's bad and then I'll ask it to retry and it's bad and then I'm sort of like you know what never mind how it was do you have like a mental model for Oh sorry go ahead
oh no go ahead i was going to move on
i was just going to say like for for like you know like um when to be specific versus not like we talked about the heristic of like I don't want to think about what I specifically want because I think the model has a good enough chance of getting it i think this is the difference between this is why it's important to learn your tools because this is this comes with sort of experience and understanding what you you know these models are currently capable with this context you know this language this project like things like that like once you get comfortable with that like I I sort of have a sense now of what it's going to crush at and what it's going to struggle at and what it's like hopeless at um and I'll retry the hopeless things once in a while to see if anything changed but for the most part like that's what's happening here is sort of like I had seen it
uh refactor sort of conditionals into like functional mappings like multiple times and I was like it's going to get this right if I just tell it that that's ugly and that was sort of the sense I had here and I think like that's one of the examples of the experience you need to build with these tools because I do see a lot of the dismissals I see with AI assisted tooling um that are on the basis of it doesn't work rather than on like some sort of other like philosophical reason if if it's on the technical basis of like this doesn't work for me a lot of the dismissals I see I'm just like you're it is sort of like a you're holding it wrong problem um you know it it's uh you know I this is getting less so but for a long time the dismissals were like chatbased zero project zero agents it was just like it was just like I asked them to solve this problem and its response hallucinated and I think we've sort of moved past that to like people are understanding that agents are the way to avoid that now but I'm still seeing a lot of like I gave it I tried to make it solve this whole issue having never used an agent before and it didn't do it and I could have done it myself faster and and like one of the things I always think of is like what tool have you ever adopted where you were immediately faster like I feel like when you adopt a new language when you adopt like a new version control system anything like you always have that period where it was easier to not use it because you know your old workflow and you sort of have to ramp up in ability before you start to reap the benefits of learning that tool and and I I feel like a lot of people still are dismissing this before they reach that point um so I think this is a good example of one of those things
yeah i mean uh the only example I can think of where I picked it up and was immediately much faster the moment I started using it was Vim boy right out the box it was just yeah like no of course not right it's like there's a long regression period um yeah
well let's talk about those so you mentioned that like there's some things that it's bad at and some things that it's hopeless at and then periodically new models will come out and you'll try it but like with the current generation so this is like the Clawude 4 you know and contemporaries um what are the things that you would still like in your experience put into the like bad or or hopeless like just do not have the agent do that because I know it's just going to be a disaster it's just going to waste my time
i mean a good one right now is is is anything more than trivial changes to Zig code bases like it's still hopeless uh with that language and so I've mentioned this online before but it you know what I usually do with a trick with Zig is it's pretty good at reading Zigg like I think cuz it's just like you know it's like if you know any language like I haven't actually uh I regret to say haven't actually learned rock but like I bet you if you like
I bet you if you threw a complicated part of the rock compiler written in rock in front of me I could tell you what it's probably doing without knowing the language right so I find that I find that LLMs are are capable of reading the zig code and logically understanding what it's what it's doing mostly uh but they're not really competent at modifying it so the the the workaround I found towards that is when it's helpful um I have it rewrite its solution in another language that it's good at whether that's C or Rust or Swift or Python sometimes it's like literally just like just write in Python and because I need to just know like this basic thing
and then I'll do the the conversion back to ZIK myself um and that's a good workound to that but it's very much like human assisted right so that's that's a hopeless example now I think this is a really cool example actually of like how you know different people's experiences with the same tools can actually differ based on the problem so that's your experience with Zigg my experience with Zig specifically on the context of the rock compiler which is of course a totally different codebase than a terminal emulator it's very like sequential like there's not a lot of complicated lifetimes for example like at all um I've actually had a very good experience with Zigg and I think mostly what that comes down to is just that like usually the types of stuff that I'm asking you to do even if it's quite complicated is very like I'm like look at these parts of the compiler i want you to apply this thing to this other part of the compiler so it has something where it's like well the LLM sort of has an understanding of like compilers in general and it's looking at big ch like meaty examples from my current codebase so even if it doesn't know Zigg super well it's got so much syntax that it's going to be following the style of from my actual codebase that putting those two together it seems to do a good job of like oh okay I can write I'm not saying it's like the most amazing code all the things you've talked about of like downsides absolutely apply but I remember in previous models doing exactly what you just talked about my go-to would be I would tell it write this in C and then okay step two port this C to Zig but I don't I don't seem to have to do that anymore with claude for mostly opus um on specifically a compiler codebase nice yeah I believe it i believe it and that it's a good example because I think that that's why the the it it's so context specific and I context you have to think of a different word because I don't mean it in terms of likel context like envir environment specific and in terms of how you use these tools yeah yeah nice okay hey so what about um stuff that's like totally hopeless where you're you're just like I am not even going to ask an LLM to do this i mean you mentioned like you know Zigg stuff as like a language but maybe something like more more broad in terms of like categories of problems uh that's like language agnostic um I mean I think it's pretty bad at architectural problems i think it's pretty bad at build i think it's good at like um it's good at copying like what folder structure should I use for like this we I've used it for like the the ghosty website this this you know I need to build a new component and react and like what folder structure it's good at like that but if you're actually like building a system and how you're going to lay out things I think it's pretty bad at that I think you still have to come up with that um and then going fully low level I think it's very still very bad at uh sort of high performance data structure type work um it's obviously so knowledgeable on standard data structures like it'll it'll it'll recommend various data structures all all day long but it doesn't understand the data structure in the context of what you're trying to achieve in order to to build the right thing and like GOI for example has some really interesting complicated variants of standard data structures like for example um the way we represent the terminal screen is through a linked list of virtual memory pages that are fixed size so that we could pull them and allocate them quickly um and then within those pages we keep them within like a 16 bit pointer distance so we only have to keep the base address and then only the offset so we could save memory on all the we don't have to store pointers we only need to store 16 bits so we could for for the size of one pointer we could store four pointers and uh we then had to combine those and unsafe load them and all this stuff and like no element I've ever tried has any idea what's going on um we we've we've built like custom hashmaps and custom trees and custom stuff on top of these offset pointer concepts and it's like so lost but it's like a critical part to how we achieve speed and cache friendliness and things like that in our codebase and so stuff like that like even with the architecture in mind with where I could guide in on exactly what it's trying to do I feel like it blows it up into this this totally different problem because it feels like it needs to rewrite these data structures and it's it's destroying performance and things like that
yeah that does seem to be the type of thing where it's like there's like mitigations you can do where you can like in your rules file try to like really explain like here's what we're doing with like 16 bits but at the end of the day the the the broader point that you made about like it just doesn't understand like by default it just wants to do something that'll get the job done without keeping your performance constraints in mind or maybe just there's it's not super well represented in its data set like doing like data oriented design type stuff like thinking about like memory CPU cache hierarchies and whatnot um and like you know memory locality as opposed to just being like pointers hooray pointers like for everything um yeah it I agree it's it's just not not good
i'm still at this point where it's it's sort of we I've sort of been a broken record on this but I just separate out like I'm still only willing to trust or not it's not trust it's just a matter of efficiency i only find it effective and efficient to use these agentic processes for mid to junior level problems um when it becomes a senior level problem like if it's a task like if I was modifying the core you know highly performance sensitive data structure of GOI and it was a company hypothetically with employees like that would even if you brought on a junior the junior would be paired with a senior on that like that's not something you get a a new grad and say like solve this problem it's just too complicated to you're setting them up for failure it's not a good thing to do um so it's like those sorts of things I would just leave out um and that's what I do with agents as well
gotcha Makes sense um
cool
i would say the other thing that's really cool that I've done I've tweeted about this with uh with LMS is because I'm making a a graphical application a gooey based application is I've taken screenshots of other programs and said reproduce this view for me cuz like I don't I don't find a lot of joy in actually like laying out the views um you know I like the business logic side I like all that but I don't like like the design part and it's like shockingly good at this sort of multimodal like here's a picture and reproduce it in Swift UI um very cool to see
yeah i I remember you Yeah you posted a thing in fact I think it was uh Zed's UI for exactly what it was yeah
it was that the command pal um so yeah exactly oh that's what it was yeah yeah yeah
right and like "Hey here's a screenshot of it in Zed like can you reproduce this in Swift UI?" And it's like "Yes I can."
Yeah yeah so Ghosty has that ships now and that was like pretty much 90% the the the view part of it was like 90 95% just AI copied it from a Z screenshot yeah
yeah and it's cool i mean like like you said earlier it's like it's the type of code that you take no joy in writing yourself and so it's nice to be able to offload that yeah
um cool uh so let's keep going uh so okay we just we just had it like you doing some cleanups here and you mentioned here like the last thing we're missing is restoring the proper focus window so this is actually um this is a behavior change right this is not just a code cleanup so was this something that you noticed like did you have this in mind from the outset or was this something that sort of like okay as you were going through with the agent you you realized oh wait a minute there's this edge case here that I didn't realize earlier and also the agent didn't pick up on its own at any point yeah so these these prior three prompts probably you know it was probably running for a couple minutes total to like process all these and so while it's doing that um I was running and just like poking at the solution trying to find bugs so that's what was happening here is by the time we got to this part I had discovered a bug and now it was time to fix that bug
yeah this is something where I mean we talked at the very beginning about like using it as sort of like a rough draft generator for like issues where you're like I have no attachment to this code it's putting out i just want to see it
i've been able to find bugs just from looking at that where I'll see like a naive implementation like oh yeah you know what I didn't think of that just from looking at the English so just having something that can spit out code that's of whatever quality can be helpful for identifying yeah these things
and this is a good example of like being able to do more than I think I would have without this because I very easily could have done these cleanups in the prior three prompts but I couldn't do those cleanups and concurrently be QA testing the the fix right and so in this case I had deferred this easy work to the AI and the whole time I wasn't context switching to something else i was still on this context alongside of it but I was running it and clicking and and stress testing it and I I found a bug so yeah
nice okay cool um so it seems like that you know the last of this is sort of like you just again asked it like broad strokes like any other cleanups or you know comments you want to you want to change and then it gave you some suggestions you rejected some others yeah even if I actually don't use agent to write code um I just manually did a whole commit when I have it committed I will usually prompt and say look at the last committed because it is get aware like I said look at the last commit I did and are there any suggestions you have and I'll just like let it spin on that um this is this is something I ask almost everything uh every piece of work I do I'll ask for that and it's found um this is sort of what I want to do in CI actually um but it it's it's found typos um even though we have like a typo checker in CI but it's found typos it's found mismatched comments with the code and it's usually we'll try to fix the comment but I've found cases where I'm like oh I actually forgot to update the code um so it's found bugs that way and so yeah it's just like a good thing or I've done a refactor and the comment like totally doesn't match what I just did in that case actually you do have to update the comments and and so I'll always ask it so I think at this point when I asked this it suggested like six or seven things um I think I only accepted one or two yeah I uh the common thing is I think an underrated um selling point of using large language models for coding because we talked about like language servers and obviously an upside of language servers that they're much more precise they don't hallucinate you know yada yada but a downside is that they really cannot have any concept of like what's going on with your comments and how they relate to the code whereas large language models will very often you like you say change this thing and it will go through and change the implementation and update the comment which is something I have many many times forgotten to do in my career
yeah and it'll find it in like other you'll it'll find I found this is the coolest part it'll find references to what just changed in another file in a comment like codebase and I'm like oh yeah that would have been out of date
um Yep
yeah it it's it's I've always had this um everyone who's ever worked with me would know this um one of the things that either like
it shocks people positively or negatively when working with me my code bases are very heavily commented um um like to the point especially if you look at like some of the core of [ __ ] that's more complicated but to the point where like every line of code will have three lines of comments um like and and early on in my career more senior people would make me delete them and say like you're just commenting what the code is doing and so this is a waste of a comment but I continued to believe that they were wrong and as I became more senior I forced this will upon everyone and I still do it in my own projects but the reason I comment so heavily is to me it's like it's I do everything twice i do it once in code and I do it once in English and and so whenever there's a PR or something if the comment doesn't match the code then one side of it is wrong and so it's like it's sort of like a fail safe check at every point of like something is wrong somewhere um what is what is it and uh I find a lot of success with it success with it and I found that with LLMs like it's gotten even better because the LMS will will do that same thing um and it also just helps guide them on what things do a little bit better so um I still do that practice and that's that's where this helps too
yeah I noticed um this last one you you asked it to write a commit message summarizing the changes and you mentioned that it like it generated part of the commit message but you always manually tweak the commit message i'm guessing the same is true of the comments where when it generates those comments you're very often going in and manually editing the comment that it generated is that right
i don't know sometimes i wouldn't say very often yeah okay i I would It matters it matters but yeah
interesting i mean most people I know delete those comments pretty aggressively that the LLM puts it but it sounds like you actually keep them and often keep them exactly as is yeah i think I'm the opposite of most people where I'll I will ask it to write more you know it it's just I I like a lot of comments um you know for people I've always said for people that worked with me if you don't like the comments editors for the past 20 years have been able to fold comments so you could hide the comments um you know like they don't need to get in the way of what you're doing but I've just time and time again on different companies different projects different phases of my life like highly I've never regretted having too many comments so yeah
yeah fair enough what about tests i mean like a lot of people feel the same way about tests that you just you know expressed about comments where it's like like quite often when I am doing something like this and kind of going back and forth with the LLM i think I would have proportionately fewer cleanup things um may maybe I would maybe I wouldn't I guess depending on the project but I definitely something that I'm like reflexively do is I'll say like write a test for this or like you know before you fix this go write a test that reproduces it and I want to see you run it so that the test fails and then after you fix it you know then I want to see the test pass without any changes to the test and I often am yelling at it in all caps about how to like do the you know red green testing um is that something you've uh tried or like are are into or not into or how do you feel about it yeah yeah i mean I think again with Zig it struggles to write Zig for my project so I tend to write the tests um but I do let it run the tests and um yeah I'm a highly test-driven person i was for better or worse
brought up in like a strict like my my junior my first programming job as a junior for three years was in a strict TDD company um and so I learned like the extreme of like
no line of code gets written before a test fails without that line of code
sweet yeah
yeah yeah i'm not that extreme i'm not that extreme but with bugs I'm I'm still pretty test driven in the sense that when there's a bug I'll write a test first and then I'll fix I'll fix the bug to pass the test um but I still find that I like to write the test myself because it gives me the understanding of what the bug is but I'll let the AI write the solution to the test that's fine
that's funny so I'm kind of the opposite where for me the thing that always frustrates me about tests is the like setting up the boilerplate around like reproducing the issue and so I I I really want to look at like every time it writes a test I'm like I will read every single character of what it wrote like carefully to make sure it's actually doing it
but I don't want to kill myself
i'll let it do some boilerplate like there was recently a ghosty bug it was actually a Zig success for it that did a good job here i think because there were so many other tests we copied from where it was a ghosty bug where when you resize the window in a certain way that broke a line that had a multi-code point uh unic code point graph theme like an emoji that took up like eight code points um it could crash under certain scenarios and I wanted to reproduce that screen state but to do it at the level where the bug was you literally had to feed it UTF8 bite at a time and I didn't I didn't want to find the bit encoding for this emoji yeah
and uh yeah so I was like I gave it I put in the comment the emoji and I said fill the screen with that emoji in a 2 x two grid and it it crushed it it did a good job on that one
gotcha nice i mean yeah that's that's really cool uh I think we're we're at time um we have some questions in the chat i've been kind of trying to sprinkle them in as we go um but I don't know if you have if you have time to to go through a couple
I could Yeah and I could go over a little bit here too to try to answer some questions so yeah
sure all right so one of these is um talking about sort of uh building skills with your tools so on the one hand you know you could have an extreme view of like I'm just going to talk to the LLM in English and not think about code at all um on the other extreme then you could say I'm not going to use LLMs for anything other than maybe asking research questions um obviously you're somewhere in between uh but how do you think about like you know developing your skills as a programmer given that like you know if you were early career and you were trying to get the intuitions that you've got for like architecture and where to draw boundaries of the system and how to give it these prompts to tell it to improve the code um obviously you know we're all still improving at everything not just you know AI usage um I don't know do do you think about that or you just kind of like just go with the flow and just sort of figure it out as you go or um well I I guess my answer to that would be that I still think it's very important to understand how things work and and what things are doing and so there's nothing I dislike more there's there's nothing that makes me more uncomfortable than like that feeling that I'm sure we've all felt when you like join a new project join a new company and you enter a codebase and you have no idea how anything works like you're capable of understanding it but you you just don't have the experience yet um it just feels so uncomfortable i hate that because I don't really know how to solve problems the right way and so I think it's still important to to h to build that understanding so I mean I think reviewing everything that an LLM does is obviously important but I tend to use the time that I get back from when it's spinning on a on a routine problem to to study other things like I'm not watching YouTube videos usually or something like that you know I'm I'm studying something else so um you know this past week um there hasn't been a lot of AI stuff like I said because of the new Mac OS announcements but while I've had some agents doing some work I've been watching the videos from the Apple announcements to try to like learn how those things work even though like in 6 months hopefully models are retrained and have some of that knowledge but um yeah I I I think you got to keep up with it and so my my advice to juniors would be like even though like especially for a lot of like cruddy apps like web apps and and a lot of JavaScript projects Python projects like AIs are really good now at generating like really working applications i would say like still challenge yourself to understand how that works even if you're not going to write it cuz uh that knowledge transfers to other projects to other languages to other environments and like I I don't know I just couldn't imagine working without that i couldn't imagine just blindly trusting um and and sort of fully vibing my way through everything yeah yeah same here for sure um when it comes to uh like task switching and context switching like you mentioned you know while the agent's spinning you'll be like watching a YouTube video catching up on the new Apple release to understand how that's going to impact Ghosty um do you have trouble with like all that context switching and just kind of like you know get getting your brain scrambled on like trying to switch between too many things at once or have you developed tactics to manage that or has it just been kind of okay in practice or
sometimes sometimes i mean I think that I think that my experience my job experience has made me pretty highly context switch capable i mean I think that as you manage more and more people like that's all you do all day is context switch like I feel like when I was like a a junior and mid-level like software engineer I got to really like sit down and focus on problems all day and then as I became more senior and especially as I got into management all I did was like oh this email is about this this email is about that i'm on this meeting about a totally completely topic like every 30 minutes i was context switching um and so I think you guys kind of get trained on that but um I think a benefit of these AI assisted tools is you don't need to respond right away you know when when Claude posts this notification makes it sound effect that it wants your attention like
I don't need to go to it if I'm heavily into something I'll keep doing it and I think that's
a nicer thing than humans like if if I was training an actual junior on the job and they had a problem whatever I'm doing I have to stop to help because there's actually like a person waiting but if I' I've gotten a ping and I'm like "Nah I'm gonna go eat dinner." Like you know like I'm not I'm not gonna I'll keep the session open the context is there like I just like go so you don't need to context switch right and I think that's a good way to think about it is keep keep doing what you're doing to to be productive and just get back to the AI whenever you want
that story just reminded me actually I don't know if you know this but Ghosty directly inspired a feature that Zeg Zed has that's uh as far as I know we're the only ones that still have this which is um I was using uh Claude Code i was trying out Claude Code and some of the other like tools um over a weekend of course I was doing it in Ghosty and I noticed that when it finished and was like blocked on something like ready for my input I got a little native Mac OS notification that popped up yeah um Yeah from from Ghosty and I was like "Oh they should all have this this is great." Like it told me visually when I'm done not just with a sound or something like that um Yeah and uh and so like I just added it to Zed and now like So if anyone's ever used the Zed feature where like the agent finishes and you get a little notification like that came from Ghosty and Claude Code
yes yeah and and Claude code directly influenced I don't know if you're on I think you're on the tip releases of Ghosty as well um but if you're not on the release version or if you're on like the tip beta releases uh Claude's usage of that inspired improvements to Ghosties that show so it used to just be persistent and so you clicked it but that was really annoying with the agent so now it has just a lot more complicated logic where if you focus the window it never shows you notification at all if you bring it into focus or move your mouse it disappears after 3 seconds it's like I did all these little things because I was getting tired of dismissing it yeah
yeah we have the switch back thing but not the like hover and it disappears after 3 seconds but yeah if you switch back to zed then it like it it hides um
y
very nice uh okay so uh another question from the chat um so uh like when you're thinking about um like working with in in this way where you're going to like do a back and forth with the agent and then like switch to you know sort of manually doing stuff what's your balance of thinking about like okay I'm going to sit down and think about this problem before I even start talking to the agent and just like kind of map out a plan of like here's how I think it should be done versus just kind of diving in and being like uh agent go and do this i'm guessing it varies by issue but
it varies by my fatigue level it's really like I find myself beginning of the day I'll sit and think about a problem and give it to the LM and honestly probably be a lot more effective and by the end of the day I know I'm running out of time to solve things i'm like I I start just throwing hailmaries and seeing what sticks at that point and again like I think one of the good things is you can just walk away like just if it's producing garbage and you're not getting anywhere I'm just like you know what screw it close that session delete the context none of it matters like let's we'll you know um we'll sleep on it and get back to it later so yeah depends
nice okay so last question from the chat and then we'll we'll wrap up because we're uh we're already over on time um have you adopted any changes to the way you like write or structure code to try to make things easier for the LLM so not just like rules files but actual like architectural changes to the code um that if you weren't using LMS you would not make
that's a really good question i I want to say definitely and I'm just having a hard time remembering how I I had this conversation with people about how it's changed the way I lay out code um I mean I I think that I'm a lot more uh like I'm a lot more aware of keeping context close um because I know that all this tooling tends to grab like the nearest lines and all this stuff so I I'm much more I always tried to do this um I learned this you know 10 years ago on the job but like I I'm much more aware of like let's move this closer let's move this into the same file even like I'll change my file layouts a little bit for it um I I want to say that with some things with the Swift app has changed out of named files as well because I found that cloud code it's sort of first task is either to like rip GP or to just like start like traversing directory trees and looking at file names and so it's sort of like changed some of that
um
well you know like I said I've always commented heavily i found that's been effective um one thing I I tweeted about which it again hasn't changed but has heavily reinforced it is the way I do refactors um I don't know when I started doing this but I've done it for at least 10 years um where when I do a refactor what I first do is I copy and paste the old implementation so I have like two versions that are fully working and I only modify one at a time um and so I you know some people refactor by like modifying the thing that they're changing or some people refactor by deleting the old thing like I have the full old thing and by the end of it the full new thing at the same time in the codebase and I' I've sort of always refactored that way um sometimes people say like some stuff's too complicated to refactor that way i will fight you on that because I've done some complicated refactors heavily intertwined and it's not like it might get to the point where you duplicate the entire pro I I did this refactor of Terraform um probably almost 10 years ago actually at this point um where I rewrote the entire parsing to execution of Terraform and it was like the whole project at that point and I literally just had you know go it was in one folder and I the Terraform folder and I just duplicated the entire Terraform folder within the same git project and I had Terraform and Terraform from two and I kept both working and I've always done that because I always want to reference the old stuff without jumping through like git hoops of finding where that last existed but with LLMs I found that it it's sort of like what you said with rock which is where uh it works a lot better when it already has patterns that you previously had and so I found with refactors even if I'm architecturally changing something it being able to see the old implementation of what it's trying to do um has made it a lot more successful so they actually uh the other commit you have open here which we don't have time to get into but if people want to look at that this commit um is where I did that um and um I I I did something like this I I refactored how splits work in Mac OS and I kept the old one and the new one until the very you could actually see the commit here it's history until like one of the last few commits um and uh one of the other things you could do is sort of at the end let's see where uh scroll up oh there it is remove the old split implementation like it was like five commits before the end out was 26 commits right up until then the old one fully existed um but sorry I got distracted but one thing you could do when you do this is one of the last prompts I gave before this commit was look at this folder and look at this folder and please tell me if I missed anything
um and you know what I'm looking for is I did a refactor i did a complicated refactor was I Yeah did I forget functionality in the new refactor u and this case I had to ask because with guey programming your ability to unit test is fairly limited so I don't have like full test coverage of this stuff so um yeah I just asked it it actually found stuff so yeah it it found stuff that uh previous to this it was actually I think it was this resize split key the the the directly previous commit i was like "Oh yeah I got to do that first before I delete the old one." Um
nice so yeah I I I think patterns like that um I would say have been re there's some new patterns but there's some also like heavily reinforced patterns that if people aren't already doing I would encourage them to to look into adopting very nice Mitchell thank you so much for your time uh this is great i learned some things i hope people watching also learn things um really appreciate you taking the time to just walk us through how you use large language models on a really really high quality project so thanks so much
thanks and thanks everyone for joining all right see you at the next one everyone 

- Collects undo states from all windows in the tab group before closing - Sorts them by their original tab index to preserve order - Clears tab group references to avoid referencing garbage collected objects - Restores all windows and re-adds them as tabs to the first window - Tracks and restores which tab was focused (or focuses the last tab if none were) AI prompts that generated this commit are below. Each separate prompt is separated by a blank line, so this session was made up with many prompts in a back-and-forth conversation. > We need to update the undo/redo implementation in > @macos/Sources/Features/Terminal/TerminalController.swift closeWindowImmediately > to handle the case that multiple windows in a tab group are closed all at once, > and to restore them as a tabbed window. To do this, I think we should collect > all the undoStates, sort them by tabIndex (null at the end), and then on j > restore, restore them one at a time but add them back to the same tabGroup. We > can't use the tab group in the undoState because it will be garbage collected > by then. To be sure, we should just set it to nil. I should note at this point that the feature already worked, but the code quality and organization wasn't up to my standards. If someone using AI were just trying to make something work, they might be done at this point. I do think this is the biggest gap I worry about with AI-assisted development: bridging between the "it works" stage at a junior quality and the "it works and is maintainable" stage at a senior quality. I suspect this will be a balance of LLMs getting better but also senior code reviewers remaining highly involved in the process. > Let's extract all the work you just did into a dedicated private method > called registerUndoForCloseWindow Manual: made some tweaks to comments, moved some lines around, didn’t change any logic. > I think we can pull the tabIndex directly from the undoState instead of > storing it in a tuple. > Instead of var undoStates, I think we can create a let undoStates and > build and filter and sort them all in a chain of functional mappings. > Okay, looking at your logic for restoration, the var firstController and > conditionals are littly messy. Can you make your own pass at cleaning those > up and I'll review and provide more specific guidance after. > Excellent. Perfect. The last thing we're missing is restoring the proper > focused window of the tab group. We should store that and make sure the > proper window is made key. If no windows were key, then we should make the > last one key. > Excellent. Any more cleanups or comments you'd recommend in the places you > changed? Notes on the last one: it gave me a bunch of suggestions, I rejected most but did accept some. > Can you write me a commit message summarizing the changes? It wrote me a part of the commit message you're reading now, but I always manually tweak the commit message and add my own flair.