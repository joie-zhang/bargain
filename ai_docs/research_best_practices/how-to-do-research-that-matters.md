# How to do Research that Matters by Lewis Hammond: Key Points

## What Makes Research Matter
- Research can matter for different reasons: salary, academic reputation, happiness, but most importantly for its positive impact on the world
- Richard Hamming's famous question: "If you're not working on an important problem and it's not likely to become important, then why are you working on it?"

## Developing a Theory of Change
- Create a structured understanding of how your research will lead to real-world impact
- Break down complex problems into smaller, tractable components
- Ensure your projects fit into a broader research agenda that explains why your work matters

## Goal-Driven vs. Idea-Driven Research
- Goal-driven (top-down): Identify where you want to go, then figure out how to get there
- Idea-driven (bottom-up): Follow the literature and fill gaps with new ideas
- Hammond recommends goal-driven research, even if taking small steps toward ambitious goals

## Finding Problems
- To get important results, ask important questions
- Look for messy, confusing areas where understanding is still developing
- "If you can't think of at least three examples of your problem, it's probably not a real problem"
- When faced with limitations, turn working around those constraints into the research problem

## Prioritizing Problems
- Difficulty is not necessarily an indicator of importance
- Consider what paths your solution would unlock, connections to other fields, and questions raised
- Work on problems suited to your comparative advantage and unique skills
- "Incremental work is the worst adjective possible in Academia"
- Quality over quantity: One substantial paper per year is better than many minor contributions

## Solving Problems
- Remain open to changing your approach and using different frameworks
- Be realistic: Balance work on important difficult problems with smaller achievable results
- Work on project components in order from most to least informative per unit time
- Focus on doing an outstanding job on a moderately sized project rather than an average job on a large one

## Common Failure Modes
1. **Not considering scaling and the "bitter lesson"**
   - General-purpose methods that scale with computation tend to outperform specific handcrafted solutions
   - Example: Neural machine translation was eventually solved by large language models with enough data and compute

2. **Making unrealistic assumptions**
   - Introduce assumptions that correspond to real-world problems
   - Ensure assumptions can be relaxed while preserving your solution
   - Avoid assuming arbitrary changes to agent objectives or unrealistic learning scenarios

3. **Working on non-neglected problems**
   - Consider the counterfactual impact: Would someone else solve this problem anyway?
   - Avoid crowded research areas and problems worth lots of money if solved
   - Be cautious about problems that have remained unsolved for decades

Hammond emphasizes that while these principles may seem obvious, consistently applying them is challenging. Even experienced researchers sometimes chase "shiny" ideas that are fun but not impactful.

---

Transcript:

Title: "How to do Research that Matters by Lewis Hammond" Transcript: "(00:04) I'm going to start uh this morning with a talk that I have never given before and that I'm quite excited to give uh and it's going to be a bunch of my uh takes quite strongly opinionated takes on what research uh I think matters and how to do research that matters I think actually for many people this is okay I'll caveat by saying that uh first of all you might think well what is Lewis you know what has he got to say about this because he is only himself a mere PhD student and that is true um and also many of the things I'm going to say to (00:40) you are going to sound really really obvious uh and yet I despite having being so keen on them and thinking them so important still routinely forget or don't kind of incorporate these into my kind of own research practices and that the way I prioritize research and so on it's very easy just to go sh chasing over chasing after shiny things that are immediately in front of you or like ideas that sound cute but that don't mean anything um because that's fun um and having doing research is a lot about having fun but some of us I think (01:14) probably most of us in this room are interested in doing research uh that is not just fun research that matters um and so yeah I think even if it sounds obvious um it's actually quite hard to kind of follow this advice and I myself have failed to do so many times in the past and I continue to fail to do so so hopefully uh you will do better than I will um yeah it's a relatively short talk um I also um welcome pushback uh and I'm going to leave questions till the end uh and if you want to chat about any of this stuff afterwards you can um (01:47) but with that said I'm going to uh jump straight in so that we're hopefully on time for our first Speaker uh in about 20 minutes how to do research that matters first thing what matters uh why what what is it for something to matter what is it for research to matter why would research matter or not okay what makes research important let's think about that first does anyone know who this person is on the screen you're going to get bonus points if that's if you do okay all right no hands and fairness I probably also would not have known I (02:20) can't couldn't remember exactly what he looked like uh this is Richard Hamming uh who you may have heard of so Hamming of like Hamming codes Hamming distance but also so like way more than that he won one of the first touring Award winners he was one of the first touring Award winners he worked on the Manhattan Project he then went to Bell Labs uh he did a bunch of amazing stuff uh very inspirational guy and he has this fantastic talk called you and your research it's a lecture that he gave relatively late in his career you can go (02:49) watch it on YouTube it's not that long I very much encourage you to do so and he has this wonderful quote from it which is if you're not working on an important problem and it's not likely to become important then why are you working on it um and this is a question that he would genuinely ask people that he was working with in Bell labs and uh I think it's uh it's a good question um so the immediate thing that it raises of course what does it mean for a problem to be important important for what uh and that you know a problem (03:18) might be important for many things so it might be uh your research might be important for your salary uh that could be important uh maybe more so thinking about your kind of academic reputation if that's something you're trying to build as a kind of early career researcher that's also can be kind of important your happiness I think you know now we're now we're getting somewhere this is more kind of more what it's about I think um but the thing I'm going to be talking about uh is this your positive impact on the world uh and (03:44) we're going to I'm going to be primarily talking about this although of course uh you know it's not to say these other things AR important and it's also to concede that unfortunately much of the time uh they will trade off against each other which is you know a sad comment on the state of the world but there we are okay next thing I want to talk about theories of change um so some of you who maybe like more familiar with kind of like strategy type things or whatever will have come across this notion of a theory of change theory of change (04:14) essentially um you can think of it almost like a kind of like a kind of flowchart esque kind of like diagrammatic picture of how the things that you are doing are going to lead to the changes and the effects that you want to see in the world and I think an incredibly valuable thing is to develop a theory of change for your own research um so Michael Ed has a wonderful talk on this uh I can share you link later if you'd like um but as an example for this you know let's just think about something in the kind of Cooperative AI (04:43) setting I'm borrowing something from Jesse here um where uh what Jesse and and his colleagues did in this paper is to kind of break down um the sources of kind of inefficiency in kind of bargaining problems and so on uh down into a set of kind of constituent Parts break the those further down break those further down Etc until you have these kind of core things like kind of okay miscoordination perceived risk of punishment kind of unconditional disclosure of information being infeasible Etc so you kind of break the (05:12) problem down uh and then you attack one of these kind of smaller parts with the knowledge that with the understanding that this is going to feed in the broader picture but it's very easy just to attack one of these parts or attack something that looks like one of these parts without fitting it into this broader picture and therefore without necessarily understanding how your research is going to make a difference which bits are most important to prioritize and so on how to break things down like this so this is a very helpful (05:37) exercise again cribbing something from some earlier slides of Jesse's um we can also incorporate these this sort of thinking into a kind of research kind of uh kind of process or flow and so on uh for doing things like a kind of pattern so you know one one way of doing things for example is thinking about like okay so we first need to think about what are the underlying conditions that are required for cooperation we then need to um uh think about the kind of Cooperative properties that those conditions are going to kind of lay the (06:09) groundwork for and so on but then of course importantly in order to know that we're actually doing anything useful we need scalable evaluation of those properties we need to be able to check that we're doing something and so again you have this kind of structured flow that indicates uh you know where the gaps in your current kind of research uh pattern might be and how to go about addressing them okay so coming up with a theory of change is important and I think that feeds more generally into uh your own agenda um and (06:38) it might come across as like a little bit weird to suggest that you all ought to have a research agenda at this point because many of you are either Junior researchers or have not even really started doing that much research yet um some of you have been doing research for a little while obviously um but even if you're only just starting out I think it's an incredibly incredibly useful exercise it has been for me personally and other people I know who have tried this to actually kind of come up with and continually refine obviously the (07:03) first time you kind of come up with this is probably going to be terrible um at least it was for me um so refining your own kind of personal research agenda I think this is especially important for those of you who are considering kind of actual kind of research careers uh where in your PhD you should not if you want your own kind of solid research career necessarily just be following on from what your supervisors are doing right you should be really kind of pushing the envelope in a bit more you should not (07:28) necessarily just be extending their research agenda genda you should have your own research agenda uh and this agenda should explain how and why your research matters so in our case this would be a theory of change for creating a positive impact um how this agenda fits into what other people are working on this is critical uh if you don't want to be scooped uh and if you want to know who the people are working on various things and also if you want to collaborate as well it's not necessarily a competitive thing um it's about (07:54) collaboration as well um and finally and almost kind of most importantly how the projects you are doing fit into that agenda so when I came up with my own kind of like little mini agenda of the stuff that I was doing I then looked back at the projects that I was working on at the moment and it didn't make any sense like there was no there was like very weak justification for why I'd be working on the projects that I was working on relative to the agenda that I kind of wanted to be pursuing or like thought I ought to pursue um and so that (08:21) led me to kind of like flipping my priorities in quite a big way um and just ditching some of those projects or like wrapping them up and not pursuing them further Etc because I realized that it was not going to be important for what I wanted to achieve um this exercise as well is both directly useful for thinking about like planning research and you know being able to pitch your ideas and you know eventually maybe some of you will end up on like The Faculty job market or something like this or like having to give a job talk (08:44) at a company or start you know even start a new orc to pursue part of the your research agenda or something like this but it's also indirectly useful in that this is an extremely kind of good exercise um for thinking about kind of how to prioritize your research how to step back look at what you're doing ask why you're doing it and take that question very seriously um relatedly um there's sometimes a distinction drawn between two kinds of research this is very crude approximation but I think it's broadly holds true one of those (09:15) types of research is called go driven research or top down uh which involves figuring out where you want to go uh identifying where you want to go and then figuring out how to get there second kind of research sometimes called bottomup research or idea driven research involves following the literature and coming up with some new ideas that haven't been tried yet um and my claim uh is that you should ideally be pursuing goal-driven research even if that means only taking small steps towards the goal right so you you might (09:43) have this big ambition uh and you might not necessarily be able to solve it uh especially if it's a big important problem big important problems are very hard to solve um but uh this is better than uh I think than kind of just you know filling in the kind of like convex hole of like research that already exists like extending things that already exist in little directions just trying to like think of like gaps like oh who hasn't tried that or like what what about this and so on that's a useful it can still be very useful don't get me wrong and (10:13) this is also much easier as well uh to do it this way right because with the gold driven thing okay first identifying the goal maybe that's okay but you have to really understand what the landscape of problems look like uh and how these kind of this theory of change is going to work and then you have to figure out like tractable bits of that problem and go on how to solve it that's very hard um but I think it's important to try and do and this is how you actually end up kind of making like a bigger difference (10:38) I think rather than just kind of being another paper on another thing that just kind of looks like well you know what if we tried this but that and so on and don't get me wrong I've done like most of all the research I've ever done has been idea driven um and that's okay as well like I don't know you start out on your research career this is like very natural thing to start by doing um but I think the more I've gone into go driven the more I feel kind of excited about my own research the more um I feel like my (11:05) research is actually going to make any sort of difference at all um where the Baseline is that it probably won't um cool okay um second uh thing of three uh doing research um this is just going to be like a list of uh some things some tips and some ideas that I find useful for thinking about how to do research I will also mention right now this feels like a good time to say this that many of the things that I'm talking about right now are stolen directly without credit uh from lots of other people's writings on how to do research (11:43) effectively um I actually have a blog post on this or like a forthcoming blog post which covers some of these topics on the slides where I link to all of these amazing resources from all of these fantastic esteemed much smarter than I am researchers um and unfortunately when I was like copying quotes from them I initially just did this as my own notes so I didn't actually attribute things very well to people during the course of taking my own notes but I do have like a massive list of a bunch of things that you can (12:09) read uh which go into way more detail about many of these things so I'm selecting some things that I found helpful for me but these resources have tons of stuff in which you might find much more helpful for you so let me know if you want me to share that with you afterwards okay doing research three stages first finding problems uh sounds really stupid and obvious but to ask to get important results you need to ask to get important results you need to ask important questions um and I'm thinking kind of like important at the level of like how (12:42) might this change the like trajectory of civilization level not like you know how can I you know make people's like experience using their like iPhones like better or whatever though that is in some ways you know potentially important you know lots of people have iPhones lots of people have phones you know all of this sort of thing but that's like kind of low stakes right I'm I'm thinking about like big picture stuff right now and I think you ought to be thinking about big picture stuff too uh look for messy and confusing areas look (13:09) for things where people sound like they don't haven't really figured out the best way to talk about this yet or they don't really know what's going on this is often uh like a key indicator of something that's kind of like ripe to be like clarified discovered uh kind of worked on and it's likely to be pretty fresh and no one else is necessarily going to know what they're talking about either so you'll be in a prime position to like swoop in and save the day uh I love this piece of advice not not mine don't invent problems if you can't think (13:36) of at least three examples of your problem then it's probably not a real problem um and time and time again I have like tried to do this with problems I've come up with and have failed uh it's a good it's a good little litmus test something else if you can't do something EG because you don't have enough computes I'm sure you as all kind of like research as all kind of compute constrained kind of students and these sorts of things might be a pretty regular occurrence for you um if you can't do something ask why not uh turn (14:05) getting around the problem that you're encountering with being able to pursue this thing as the thing you're actually trying to solve uh I think this is a really nice idea um and then I also want to say that actually something just like finding a new different lens on a problem uh can itself be a uh kind of meaningful contribution and so on uh there's lots of ways to make progress on Research that don't look like there's lots of ways to make important contributions that don't look like kind of conventional blah blah blah like (14:34) setting motivation methodology results blah blah blah type work uh and you don't necessarily have to fall into that pattern to do impactful things and in fact many of the more impactful bits of research are in fact things that look a bit like this this kind of reframing adopting a different lens joining to different areas and so on okay second uh of three things so finding finding problems prioritizing problems so you found a bunch of problems and some of them seem okay how should you prioritize them first first (15:04) thing which is pretty obvious is like difficulty is not necessarily a good indicator of importance so don't just like try and solve something that seems like hard uh because it might not matter um instead think about these things think about the areas opened up or the paths unlocked by this new result if you were able to solve it this new problem if you're able to unlock it think about Connections uncovered to other fields and other kind of disciplines other ideas um think about the the questions actually raised by solving the problem (15:32) if you're able to show some kind of result positive or negative or whatever what new questions does that throw up this is how progress is made uh and also of course especially when you're earlier on in your career you ought to as well pay some kind of attention to the skills gained uh in doing the thing you know a great way to like learn about a thing is to force yourself to do a project in that thing uh and that's you know something I've done a bunch of times like didn't know any RL did a project in RL didn't know anything about causality (16:01) did a project in causality now I know about RL and causality great news lucky me um work on problems that are suited to you think about your comparative advantage again this is just like super obvious advice but like actually think about it it took me maybe like one and a half years as a PhD re researcher before I kind of like realized like what I can do better when it comes to doing research or working on Pro problems and papers compared to my colleagues and also the things I couldn't do as well right um and so I've sort of Switched (16:34) now a little bit into doing the things that I am a bit better at when it comes to research but I could just have like never really noticed that or like it took me a while to like pay attention to that um and I could have easily just like continued doing like just standard stuff without thinking about like actually no or this is also useful for thinking about collaborations and so on like what can you bring to the table uh some people like to call like you know what is what is your like secret weapon almost like what is your unfair (16:59) advantage that you have other over over other people and how are you going to use that to deliver the most impactful results that you can this is another of my favorite quotes incremental work is the worst adjective possible in Academia this is not my this is I'm quoting someone else uh but I I like it I think it's like to a first approximation correct um and this also relates quite closely to this idea of idea driven versus like gold driven research though not entirely can think about incremental steps towards a (17:31) goal and that is not necessarily quite so bad um but yeah uh it can be tempting especially when you see people around you like writing lots of papers or publishing lots of things etc etc to get uh caught up in that rat race and to just try and like you know think about quantity over quality um that is actually a not what matters for uh kind of actually making progress on things and also B when you get to things like applying for posts applying for jobs applying for whatever this is this also like doesn't look good necessarily from (18:07) the perspective of like hiring committees right like if you're on a hiring committee what you're looking for is your they they care about like the two or three like best things that you did in your PhD or in your like previous research career or whatever um like another thing another piece of advice that I don't have on here um but like ideally after your PhD or for instance if you're going to do a PhD or something like this if going to do a bit of research you should be known as the person who did X right where hopefully X (18:34) is something like actually useful uh but that's like the one of the like best possible outcomes that can arise from your PhD um but X doesn't need to be like you know tons of little different things it could just be like one cool really big thing um you know like Ian Goodfellow the guy who did Gans right uh like things like this obviously not any of us we're not necessarily all Ian Good Fellows that's fine uh but you know I think it's worth it's worth thinking about what this means um and you know if you write one good paper a year and it's (19:07) really solid and chunky and it's a meaningful contribution you're smashing it that's great um and I think many people decide that they want to do try and do many more things than that and then they end up going for quantity over quality okay final bit on um thanks water uh final bit on um uh solving problems uh sorry can't remember what what this is about now maybe it was solving problems and maybe this is also a slide is called solving problems anyway whatever um remain open to changing your approach um so like many (19:39) of us myself included have like favorite framings favorite methods you know as soon as I hear a problem I want to write it down in terms of you know a particular model of a game or like a particular like learning problem or whatever it might be and be open to like throwing that away and to trying something different um because that just yeah that will actually that can often really help uh it it helps a lot more if you're working with someone as well who is used to adopting different frames or modeling problems in different ways and (20:07) can help you see things from a different perspective it's very useful um be realistic um your all early stage career early kind of researchers and so on like solving big important problems is like really hard you probably won't be able to do it uh or like at least like the big thing like at least straight away unless you're some like super genius in which you don't in which case you can just ignore everything I've been telling you anyway um so just that's fine that's fine though so just balance work spent on (20:34) important difficult problems with smaller more easily achievable results and as you skill up on as a researcher those bigger important problems you will find them more and more tractable and this is just like how you grow and uh uh gain kind of skills as a researcher that's totally fine um this is a really nice piece of advice which I think is I cribed from Jacob steinhardt who's a professor at Berkeley um so when you're thinking about a project and it's component parts which you you should ideally be laying out in front of you (21:02) before you actually get started on it um what you should do is you should work on the components of the project in the order from most to least informative per unit time uh how should you measure that you should measure that in terms of the failure rate expected from that bit or the expected time solved saved not necessarily by starting with the easiest part or the hardest part or something else the idea being that um if there's some component of the project where if it doesn't really work the project is not really going to go anywhere uh you (21:28) should find that out first right and that might mean doing something you know like starting with a few kind of you know cheap experiments as opposed to like laying out some of the formal Theory and like setting up the model and stuff like that maybe you should actually just kind of jump in halfway through to test if something is actually going to be like at all tractable before you decide to like embark on this project more generally uh and this is more important when you start having more research ideas than you actually (21:56) have time to work on and there's like a changing point uh at some point during your kind of like research progress when this will happen for some of you it might have already happened for some of you it might not have happened just yet that's totally fine you're all at very different stages um this happened to me like maybe like I don't know one year into my PhD or like one and a half years into my PhD with some people it takes more time some people takes way less time I met people on the first day of my PhD who are like well I've got these (22:21) like 10 like problems and they were all like amazing like cool research directions and they didn't have time to work on them um but yeah so this is important for doing that when you get to that stage um and again this is like such like standard boring advice uh that applies to like actually most things but it's still just worth repeating because people routinely fail to take it into account including me uh it's far better to do an outstanding job on a moderately sized project and an average job on a large project and again this is about (22:48) this quality over quantity thing okay final thing I want to do I realize I'm running a little bit over and I don't want to take up too much time of EDS because it's going to prove it promises to be excellent as always always um common failure modes things that people don't that people do like three things that people fail to take account of When selecting research problems when things when doing things like this I'm going to run through this relatively quickly there's going to be some examples um okay first thing not (23:14) paying attention to scaling and the bitter lesson so some of you might have already gnome's giving a talk later he's a big proponent of the bitter lesson uh he routin he like tweets like semi-regularly about how people should be thinking about the bit a lesson um and and uh for those of you who aren't familiar with the bit lesson a Google it it's on Rich Sutton's website you should actually read it it's very very short um and essentially it's about how general purpose methods that scale with increased computation tend to over time (23:44) outperform more specific handcrafted unscalable methods so this is very relevant for example when we think about the progress of deep learning but people often over index on that and think oh it's just all about machine learning blah blah blah but it's not it's also about you know one of the key things that uh Rich Sutton makes in this blog post it's also about things like search as well other sorts of kind of like algorithmic methods and techniques Etc that tend to be pretty General and scale very well with (24:08) computation um and these things are important okay so what are some examples of work that you can do that does pay attention to scaling in the bit of lesson or is not really adversely affected by scaling in the bit of lesson well you know one example might be the fact that meta learning a model-free optimization and things like opponent shaping uh you know you just throw more compu the problem uh you uh don't worry about like doing anything like clever or whatever uh it just you know eventually it just works um and you (24:36) know this is something people who can worked on this thing can attest to um another thing that isn't necessarily so affected by scaling the bit of lesson is things like interpretability for example like just because something gets like uh you know more computation is used or there's some like bigger more complex thing sometimes that can almost make the thing less interpretable right and so working on interpretability is like a fine way to like avoid getting hit by scaling by scaling issues in the bit of lesson okay what's what are negative (25:03) examples so what are things that I would not recommend doing uh if you want to take account of this these are mostly historic examples okay neural machine translation turns out that was a waste of time uh no offense to anyone who worked on neural machine translation it wasn't truly a waste of time obviously there was progress made there were many insights gained and so on but turns out we just shove uh you know enough data and enough compute at a large language model and we get neural machine in translation for free hooray um other (25:32) things learning to play cooperatively based on humans by kind of handcrafted representations of conventions and so on humans have all sorts of conventions uh and you know it's important to take account of them and it's highly non-trivial for uh machines to kind of interact with us and to pay attention to those conventions uh but if with enough data about those conventions and with enough compute thrown at the problem this kind of eventually kind of Fades away and some of this I'm kind of talking like I'm not saying these (26:00) problems are necessarily like solved right now I'm saying we should expect them to fall out of General capabilities advances in the coming years okay third second of three kind of things that I think that people often fail on unrealistic assumptions so to make important problems tractable you often have to introduce assumptions about those problems right this is just a natural thing you do um the trick is of course here to introduce good assumptions what does it mean for an assumption to be good well it depends on (26:27) how closely that assumption corresponds to the problems that actually matter in the world if you have to make some assumption about something which is then like means that it only really applies to like small edge cases that no one really cares about or that don't make that much difference then so what um and also thinking about how easily it can potentially be relaxed while preserving the solution that you come up with totally fine to make a bunch of assumptions come up with a kind of like weaker version of the problem as long as (26:52) it's like clear that you've solved the core of the problem that much and you can kind of you know eventually do some Pro you know you can leave someone else to like fill in the gaps or whatever or like you know you can do some follow-up work to like strengthen it but yeah that's a core idea okay so positive examples good good assumptions that you might come up with so not always the case but like you know maybe uh you want to adopt a meal mean field approach uh to thinking about population so basically like take the limit of like an (27:16) infinite number of Agents of course we don't have an infinite number of agents in practice but often this is like a reasonable assumption and you can kind of bound the difference between what you're coming up with and a large population of Agents other things maybe you want to assume that a group of Agents plays a aash equilibrium at some point um now that's actually can be quite unrealistic in many settings um because for various reasons that I'm not going to go into right now um but if you can kind of roughly like just plug in (27:43) any other sort of solution concept and the thing pretty much just works the same um and it doesn't really matter that much then that's totally fine stick with the Nash equilibrium people use it it's okay negative examples um sometimes people are like oh how can I get my agents to cooperate well I can just like perturb their reward function or whatever I can give them a little bits of auxiliary rewards I can make them care about this that and the other um but people take this too far people just assume that like oh we can just do like (28:09) more or less like arbitrary like changes to their objective functions and so on and in a general Su setting and like why would that ever be the case why would you be able to do that what is the mechanism via which you are going to enforce that if I have my agent and you have your agent and we deploy them in the world and I want my agent to be pursuing my objectives you want your agent to pursuing your objectives why am I going to listen to someone who says no no no no no just just tweak your reward function so that it like you know cares (28:35) more about that other agent or like does something else right that might be possible we might be able to enforce that but you have that's a strong assumption um and so often people who take this kind of top- down approach to solving these cooperation problems kind of ignore the fact that they have this privileged position of working on it as a kind of system designer that is just going to be totally unrealistic when it comes to real world agents deployed at scale um another silly example of this is like assuming that in your problem (29:02) case agents are going to have to learn to communicate with one another tabular rasa by which I mean uh they're just going to like they're going to have no idea how to communicate they're just going to have to figure this out by themselves blah blah blah blah blah like once upon a time maybe that's like a reasonable assumption now we have language models there's just no way there's no reason why this would be the case anymore um so like don't you know don't make something a problem if it's not actually likely to be a problem (29:29) right final thing uh then I'll wrap up and pass on sorry for running late Ed uh non- neglected um so when thinking about the impact of your work I claim that what you should actually be thinking about is the counterfactual expected impact of your work so expected means this can sometimes imply taking bigger bets uh riskier bets and so on this is hard to do early in your research career um because you're trying to build up progress I think it's still worth doing or like pushing yourself to go in that direction counterfactual thing is kind (29:59) of more critical uh the idea basically here is that if someone else is going to have soon solved the problem that you are solving anyway then basically you didn't really make that much difference and now lots of problems are going to get solved over time anyway this is pretty natural this is how science advances um but and so it's more thinking about how much you accelerate things how much of a difference you make in that sense um but uh yeah this is this is like if you want to actually have an impact in the world then you (30:23) should be thinking about your counterfactual impact um so therefore you should be wary of problem s that have lots of people working on them uh like stay away from crowded areas if you can this will also improve your sanity as a PhD student because you won't be having sleepless nights worrying about like all the other thousands of people working on exactly the same thing that you are working on all trying to submit to newps all looking to scoop each other and so on which is a horrible position to be in I know I've been in it um also (30:50) tend to try to ignore problems that will be worth lots of money if they're solved why because people are already going to be trying to solve them and people probably much more well-resourced than you uh a PhD student other things try and ignore to the extent that it's possible problems that have lay lay unsolved for decades I don't want to say this too strongly because I actually do think that just you know these problems do need fresh eyes they do need attention and so on um and it's also you know potentially the (31:20) case that you can make progress and so on and you can you can tackle these things uh you know sometimes other research advantages unlock things that you can then use to tackle these problems and so this is more this is a bit of a weaker advice but ese especially when you're like starting out with your PhD trying to like just tackle like the biggest outstanding problems in the field is like not necessarily a very sensible thing to do and again also because lots of other people have tried and mostly failed to do that okay so (31:47) what are some positive examples of like things I think are like neglected but that like you know are could important to work on from the point of view of Cooperative AI stuff like understanding the implications of Agents written an overlapping code code for cooperation so you know maybe you have two agents distilled from like the same base model or whatever as a language model um and like what does that imply for like how they're going to interact with one another people are no one like very very few people are really thinking about (32:10) that that could be just like a really critical and important thing um stuff like commitment and Contracting between agents like I don't know this is like not that important right now because of the ways in which agents interact but as soon as they're kind of doing things in the real world for us like forming these agreements and forming this trust between agents it's going to be super important uh but there's a whole infrastructure that's needed there that just like people haven't built yet negative examples (32:35) things you shouldn't do creating an llm meeting assistant that moderates meetings and discussions yay but it's helping with cooperation and it's using language models which is like at the frontier so this is really cool well great apart from like a billion other people are already trying to do this and many of them have like startups and are like throwing a bunch of money at it and we're going to have this in like 6 to n months anyway uh and so just like working on it as a p PhD student is like basically pointless um helping (33:02) self-driving cars to coordinate at Junctions the self-driving car companies are just going to figure this out right you don't need this is you're not going to help anything by like figuring this out um a also it's like just not that big of a deal uh like yes no one likes car crashes but like this is this problem is just going to be solved um so like don't worry about it this is not your problem to solve um okay I feel like I ended the presentation on kind like a bit of a downer which I didn't really want to do I was just kind of (33:31) like being mean about research directions um I think it's actually best if I don't hand over questions right now but if you want to talk about any of this stuff you should come chat to me in the break"